---
title: "OHI 2021: Artisanal Opportunities, Preparing non-industrial catch data for BBmsy calculations"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 1
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '../../../workflow/templates/ohi_hdr.html'
pdf_document:
  toc: true
editor_options: 
  chunk_output_type: console
---

# Summary

This script takes the Watson 2020 (v5.0) catch data, provided at a resolution of half-degree cells globally, and creates 1 data layer:

1. An average non-industrial catch dataset used to weight B/Bmsy values in the fisheries model. For this dataset, the catch is assigned to FAO and OHI regions.

**IMPORTANT NOTE: the fisheries subgoal and fisheries pressure data preps will need to be run first before this can be completed. That is where the RAM stock status dataprep and the fisheries catch download occurs.**

## Updates from previous assessment
This is a new layer for the artisanal opportunities goal

***

# Data Source

**Reference**: Watson, R. A. and Tidd, A. 2019. Mapping nearly a century and a half of global marine fishing: 1869â€“2017. Marine Policy, 93, pp. 171-177. [(Paper URL)](https://doi.org/10.1016/j.marpol.2018.04.023)

**Downloaded**: December 11, 2019 from [IMAS portal](http://data.imas.utas.edu.au/portal/search?uuid=ff1274e1-c0ab-411b-a8a2-5a12eb27f2c0) - click on download tab, step 3

**Description**:  Global fisheries landings data per cell separated by Industrial versus Non-Industrial catch, IUU, and discards.

**Native data resolution**:   

**Time range**: 1950 - 2017

**Format**:  CSV format

**Additional Information**: [Metadata](http://metadata.imas.utas.edu.au/geonetwork/srv/eng/metadata.show), [Supplementary Material](https://ars.els-cdn.com/content/image/1-s2.0-S0308597X18300605-mmc1.docx)
***

## Setup

Note: the same data was used to prepare fishing pressures (prs_fish). We will be using annual catch .rds files prepared in the mazu prs_fish folder. This means that prs_fish will also need to be run before this. 

``` {r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'figs/',message = FALSE, warning = FALSE, echo = TRUE, eval=FALSE)
```

```{r, eval=FALSE}
## Libraries
library(readr)
library(dplyr)
library(raster)
library(parallel)
library(purrr)
library(stringr)
library(tidyr)
library(foreach)
library(here)
library(sf)
library(tidyverse)
library(maps)
library(readxl)

setwd(here::here("globalprep/ao/v2021"))
source('../../../workflow/R/common.R')

## Paths for data
path_data = file.path(dir_M,"git-annex/globalprep/prs_fish/v2020/int") # use 2020 files since we didn't update to new fisheries data in 2021
fis_path = file.path(dir_M,"git-annex/globalprep/fis/v2021/int") # filepath to fisheries path
IMAS_d2020 <- file.path(dir_M, "git-annex/globalprep/_raw_data/IMAS_GlobalFisheriesLandings/d2020") # filepath to raw fisheries data

```

***

# Load Data 

## Non-Industrial Catch

The raw Watson data is separated into industrial and non-industrial fishing. We will only grab the non-industrial catch for Artisanal Opportunities. The non-industrial catch files are downloaded and prepped in the prs_fish/ folder. 


Look at catch data
```{r, eval=FALSE}


years <- c(1950:2017)
data_files <- list.files(file.path(path_data, "annual_catch"), pattern = "NInd", full.names = T)

## read in one of the catch data
catch <- readRDS(file.path(path_data, "annual_catch","NIndCatch_2015.rds"))
sort(unique(catch$CountryName))

test <- catch %>%
  filter(CountryName == "Sweden")

```

## Read in Cells Datatable

This file is created in the fisheries data prep, in **clean_cells.Rmd**. It will be used later to align the catch data with appropriate regiosn. 


```{r load_data, eval=F}

cells <- read.csv(file.path('../../fis/v2021/int/cells.csv'))
head(cells)

```

# Aggregate Nonindustrial catch

Aggregate catch per OHI region and FAO area. This catch will be used twice. 

(1) The catch is used to weight scores per region. For this we need to use catch records, including those not reported at the species level. See note below.

(2) The catch data at species level is used to calculate stock status (BBmsy) per stock (remember that our definition of a stock is a species caught within a single FAO area).


Note:  Save IUU and Reported only (`CatchTotal`) as the catch sum. 

**NonIndustrial Catch**
```{r, eval=FALSE}

## list all data files
data_files <- list.files(file.path(path_data, "annual_catch"), pattern = "NInd", full.names = T)


## function to wrangle data into what we need (total catch per OHI region per stock)
stock_rgn_total <- function(file) {  
  #file = data_files[68]

  catch <- readRDS(file)

  
  # test <- output_df %>%
  #   filter(rgn_id == 235)

    
output_df <- catch %>% 
    dplyr::mutate(CatchTotal = IUU + Reported) %>% 
    dplyr::select(year = Year, TaxonName, CommonName, Cell, CatchTotal) %>%
    dplyr::rename(CellID = Cell) %>% # match what is in cells.csv
    dplyr::left_join(cells, by = "CellID") %>%
    dplyr::mutate(catch_prop = CatchTotal * area) %>% # no NAs - every cell ID matches
    dplyr::group_by(year, rgn_id, fao_id, TaxonName, CommonName) %>%
    dplyr::summarise(catch = sum(CatchTotal)) %>% 
    dplyr::ungroup() %>%
    dplyr::mutate(stock_id = gsub(" ", "_", paste(TaxonName, fao_id, sep='-'), fixed=TRUE))%>%
    dplyr::rename(fao_rgn  = fao_id,
                  tons     = catch)

return(output_df)

}

total_catch <- purrr::map_df(data_files, stock_rgn_total)

# missing <- c("Belgium", "Latvia", "Estonia", "Kerguelen Islands", "Faeroe Islands", "Iceland", "Finland",           "Poland", "Lithuania", "Sweden")
# 
# test <- total_catch %>%
#   left_join(rgns_eez) %>%
#   filter(rgn_name %in% missing)

write.csv(total_catch, file = file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn.csv'), row.names=FALSE)

```

## Add Taxon Key Information

Need taxon key to easily remove higher level (e.g. genus) taxonomic catch data. Unique taxon key was extracted from Watson 2019 (v5) Codes.xlsx, sheet name "Taxa".



```{r, eval=FALSE}

taxonkey <- read_excel(file.path(IMAS_d2020, "Codes.xlsx"), sheet = "Taxa")

taxonkey[duplicated(taxonkey[,2:3]),] ## this shows that there is one TaxonName/CommonName that are the same, with two different TaxonKeys... 

# # A tibble: 1 x 7
#   Taxonkey TaxonName            CommonName      Descript TaxLevel ISSCAAP ISSCAAPName   
#      <dbl> <chr>                <chr>           <chr>       <dbl>   <dbl> <chr>         
# 1   690288 Xiphopenaeus kroyeri Atlantic seabob shrimp          6      45 Shrimps prawns

stock_rgn <- read_csv(file.path(dir_M,'git-annex/globalprep/fis/v2021/int/stock_catch_by_rgn.csv')) ## grab the taxon key info from the fisheries dataprep

## check diffs 
setdiff(paste(taxonkey$TaxonName, taxonkey$CommonName), 
        paste(stock_rgn$TaxonName, stock_rgn$CommonName)) ## no mismatches
no_taxonkey <- setdiff(paste(stock_rgn$TaxonName,stock_rgn$CommonName), 
                       paste(taxonkey$TaxonName, taxonkey$CommonName)) ## EMPTY - they all have a match! 

new_taxa <- stock_rgn %>% 
  filter(paste(stock_rgn$TaxonName, stock_rgn$CommonName) %in% no_taxonkey) %>%
  dplyr::select(TaxonName, CommonName) %>%
  unique() ## All taxa match... good. 

taxonkey <- rbind(taxonkey, new_taxa) 

write.csv(taxonkey, "intermediate/watson_taxon_key_v2021_ao.csv", row.names=FALSE)
```


Add taxa to the stock catch by region.

```{r, eval=FALSE}

## read in modified taxon key table
taxonkey <- read.csv("intermediate/watson_taxon_key_v2021_ao.csv", stringsAsFactors = FALSE)

stock_rgn <- read_csv(file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn.csv'))

# check
setdiff(paste(taxonkey$TaxonName, taxonkey$CommonName), 
        paste(stock_rgn$TaxonName, stock_rgn$CommonName)) # Lots of differences here... this is because the taxonkey contains INDUSTRIAL catch.. so all of the mismatches are industrial caught spps
setdiff(paste(stock_rgn$TaxonName, stock_rgn$CommonName), 
  paste(taxonkey$TaxonName, taxonkey$CommonName)) # any diffs here will need to be corrected - there are none 


stock_rgn_taxa <- stock_rgn %>% 
  left_join(taxonkey, by = c("TaxonName","CommonName"))

summary(stock_rgn_taxa) # there should be no NAs for Taxonkey

write.csv(stock_rgn_taxa, file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn_taxa.csv'), row.names=FALSE)

```

## Data Check

Take a look at catch data with missing ohi and fao regions in **stock_catch_by_rgn_taxa**. These have taxon key matches, but no ohi or fao regions assigned to them. 
```{r, eval=FALSE}
region_data()

df <- read_csv(file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn_taxa.csv')) %>%
  left_join(rgns_eez)

sort(unique(df$rgn_name))

missing <- c("Belgium", "Latvia", "Estonia", "Kerguelen Islands", "Faeroe Islands", "Iceland", "Finland",           "Poland", "Lithuania", "Sweden")

test <- df %>%
  filter(rgn_name %in% missing)
sort(unique(test$rgn_name))
sort(missing)

# 32 NAs for OHI regions
df_na <- df %>% 
  filter(is.na(rgn_id))
nrow(df_na)

# 21416 catch data without fao regions assigned - v2021
df_na <- df %>% 
  filter(is.na(fao_rgn))
nrow(df_na)

```

Check NA values before taxa was added
```{r, eval=FALSE}
## before adding in taxa info
stock_rgn <- read_csv(file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn.csv'))

## 32 NA - v2021
stock_na <- stock_rgn %>%
  filter(is.na(rgn_id))
nrow(stock_na)

## 21415 NAs - v2021
stock_na <- stock_rgn %>%
  filter(is.na(fao_rgn))
nrow(stock_na)

```

Look at summary info for original catch file and output after joining to cells.csv
```{r, eval=FALSE}
catch <- readRDS(file.path(path_data, "annual_catch","NIndCatch_2015.rds"))

summary(catch) # no NAs

output_df <- catch %>% 
    dplyr::mutate(CatchTotal = IUU + Reported) %>% 
    dplyr::select(Year, TaxonName, CommonName, Cell, CatchTotal) %>%
    dplyr::rename(CellID = Cell) %>% # match what is in cells.csv
    dplyr::left_join(cells)

summary(output_df) # FAO ID 3273 NAs - v2021

## after fix cells.csv, 126 NAs in ohi rgns
output_na <- output_df %>% 
  filter(is.na(fao_id)|is.na(rgn_id)) # extract just the rows with NAs

summary(output_na)
```

Look at which cells we are missing ohi and fao regions for in the 2014 catch. Looks like all of the cells in Watson catch with missing FAO regions are on land along the coastline, especially in Antarctica. 

```{r, eval=FALSE}
#create a raster of Cell numbers
## This Codes.xlsx was downloaded from the same place as the raw Watson data.
cells <- read_excel(file.path(IMAS_d2020, "Codes.xlsx"), sheet = "Cell") %>%
  dplyr::rename(x = LonCentre,  y = LatCentre, z = Cell) %>% #I renamed these xyz to use in the rasterFromXYZ() function below
  dplyr::select(x,y,z)

#turn the lat/long points into a raster
cells_raster <- rasterFromXYZ(cells)

crs(cells_raster) <- "+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0" 

cell_na <- unique(data.frame(cell_id = output_na$CellID, value = 1)) # set random value for viewing
cell_na_plot <- raster::subs(cells_raster, cell_na, by = "cell_id", which = "value", subsWithNA=TRUE)

maps::map('legacy_world') 
plot(cell_na_plot, add=TRUE)

```

***

***

# Prep data for mean catch 

## Wrangle

Mean catch data is used to weight the B/Bmsy values in the fishery subgoal.

```{r mean catch, eval=F}

file <- file.path(dir_M,'git-annex/globalprep/ao/v2021/int/ao_stock_catch_by_rgn_taxa.csv')

catch <- read_csv(file) %>%
  rename(common = CommonName, fao_id = fao_rgn, species=TaxonName)

summary(catch)


## filter out non ohi eez regions 
catch <- catch %>%
  filter(!is.na(rgn_id)) %>%
  filter(!is.na(fao_id)) %>%
  filter(rgn_id <= 250) %>%
  filter(rgn_id != 213)


## calculate total annual catch for each stock
catch <- catch %>%
  dplyr::select(year, rgn_id, fao_id, stock_id, Taxonkey, tons) %>%
  group_by(rgn_id, fao_id, Taxonkey, stock_id, year) %>%
  summarize(catch = sum(tons)) %>%
  ungroup()


missing <- c("Belgium", "Latvia", "Estonia", "Kerguelen Islands", "Faeroe Islands", "Iceland", "Finland",           "Poland", "Lithuania", "Sweden")

test <- catch %>%
  left_join(rgns_eez) %>%
  filter(rgn_name %in% missing)
sort(unique(test$rgn_name))
sort(missing)

```

Take a look at a few stocks.
```{r, eval=FALSE}

data.frame(dplyr::filter(catch, stock_id == "Marine_fishes_not_identified-57" & rgn_id==1))

```

## Fill in Zeros
For years with no reported catch, add zero values (after first reported catch)

```{r, eval=FALSE}

## these data have no zero catch values, so add years with no reported catch to data table:
catch_zeros <- catch %>%
  spread(year, catch) %>%
  data.frame() %>%
  gather("year", "catch", num_range("X", min(catch$year):max(catch$year))) %>%
  mutate(year = as.numeric(gsub("X", "", year))) %>%
  mutate(catch = ifelse(is.na(catch), 0, catch))

## this part eliminates the zero catch values prior to the first reported non-zero catch   
catch_zeros <- catch_zeros %>%
  group_by(fao_id, Taxonkey, stock_id, rgn_id) %>%
  arrange(year) %>%
  mutate(cum_catch = cumsum(catch)) %>%
  filter(cum_catch > 0) %>%
  dplyr::select(-cum_catch) %>%
  ungroup()

```

## Calculate Mean Catch
Calculate mean catch for ohi regions (using data from 1980 onward). These data are used to weight the RAM b/bmsy values.

```{r, eval=FALSE}

mean_catch <- catch_zeros %>%
  filter(year >= 1980) %>%
  group_by(rgn_id, fao_id, Taxonkey, stock_id) %>%
  mutate(mean_catch = mean(catch, na.rm=TRUE)) %>% # mean catch for each stock (in a specific ohi-fao region)
  filter(mean_catch != 0)  %>%      ## some stocks have no reported catch for time period
  ungroup()



```

Check out the data
```{r, eval=FALSE}

data.frame(filter(mean_catch, stock_id == "Marine_fishes_not_identified-57" & rgn_id==1)) # includes finfishes (100139) and other marine fishes (100039)
```

## Toolbox formatting and save

```{r, eval=FALSE}
options(scipen = 999) # to prevent taxonkey from turning into scientific notation

mean_catch_toolbox <- mean_catch %>%
  mutate(stock_id_taxonkey = paste(stock_id, Taxonkey, sep="_")) %>%
  dplyr::select(rgn_id, stock_id_taxonkey, year, mean_catch) %>%
  filter(year >= 2001) %>%  # filter to include only analysis years
  data.frame()

write.csv(mean_catch_toolbox, "intermediate/mean_catch.csv", row.names=FALSE) ## save the total mean catch csv for reference if needed

```



***
